{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floating-latex",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use the GP to Predict Team Season Results Using Player Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import ipdb\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "import warnings\n",
    "import sys\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import chart_studio.plotly as ply\n",
    "import chart_studio.tools as plytool\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as plyoff\n",
    "import plotly.subplots as plysub\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my imports\n",
    "#sys.path.append('../src/')\n",
    "from util.Utils import *\n",
    "from GP.GP import *\n",
    "from GP.FunctionTree import *\n",
    "from GP.Objective import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-october",
   "metadata": {},
   "source": [
    "## Load and Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' load the data '''\n",
    "# open\n",
    "dbFile = '../data/baseballdata.db'\n",
    "dbConn = sqlite3.connect(dbFile)\n",
    "# query\n",
    "sql = 'SELECT * FROM NLALRegularSeasonTeamStatsRanks;'\n",
    "data = pd.read_sql(sql, dbConn)\n",
    "display(data.head())\n",
    "# close\n",
    "dbConn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' final data prep ''' \n",
    "# drop a few columns\n",
    "data.drop(columns=['_G', '_L'], inplace=True)\n",
    "# encode division & league win columns as binary\n",
    "data['_DivWin'] = np.where(data['_DivWin'] == 'Y', True, False)\n",
    "data['_LgWin'] = np.where(data['_LgWin'] == 'Y', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping pitcher's wins & losses for obvious reasons; can add this back when using year t stats\n",
    "# to predict year t+1 performance\n",
    "data.drop(columns=['P_Win', 'P_Loss'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frozen-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column roles\n",
    "colID = ['_yearID', '_lgID', '_difID', '_teamID', 'Team']\n",
    "colResp = ['_Rank', '_divWin', '_LgWin', 'WinPerc', 'WinLosPerc'] # all potentially useful targets\n",
    "respTypes = ['C', 'C', 'C', 'R', 'R']\n",
    "colPred = [col for col in data.columns if col[:2] in ['F_', 'B_', 'P_']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-expense",
   "metadata": {},
   "source": [
    "## Run the GP\n",
    "### How do player stats best relate to team performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offensive-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_Rank', '_divWin', '_LgWin', 'WinPerc', 'WinLosPerc']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the index of the potential response column to use:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reponse = WinPerc(R)\n"
     ]
    }
   ],
   "source": [
    "# set the target column\n",
    "print(colResp)\n",
    "resp = int(input('Enter the index of the potential response column to use: '))\n",
    "response = colResp[resp]\n",
    "respType = respTypes[resp]\n",
    "print('Reponse = %s(%s)'%(response, respType))\n",
    "data['target'] = data[response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' prepare GP input parameters '''\n",
    "# GP parameters\n",
    "parmsGP = {'showTopSubs':10, 'populSize':500, 'numGens':200, 'noChangeTerm':180, 'convgCrit':0.00001,\n",
    "           'elitism':True, 'mateType':1, 'probXover':0.8, 'probMutate':0.3, 'plotFlag':True,\n",
    "           'printFreq':10, 'maxDepth':4, 'probPrune':0.4, 'probSimp':0.2}\n",
    "# data parameters\n",
    "parmsData = {'data':data, 'name':'NLALRegularSeasonTeamStatsRanks_%s'%response}\n",
    "\n",
    "# set the possible node values\n",
    "ops = ['ad', 'sb', 'ml', 'dv', 'pw', 'mx', 'mn']\n",
    "consts = [0, 1, 2, 3, 10, 100]\n",
    "nodeMeta = OrderedDict() # must be orderd by descending weight - [values, length, weight] \n",
    "nodeMeta['op'] = [ops, len(ops), 0.5]\n",
    "nodeMeta['feat'] = [colPred, len(colPred), 0.25]\n",
    "nodeMeta['const'] = [consts, len(consts), 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' objective parameters '''\n",
    "if respType == 'R':\n",
    "    # for a continuous target\n",
    "    estim = LinearRegression(fit_intercept=False)\n",
    "    parmsGP['optimGoal'] = -1\n",
    "    parmsObj = {'function':'TreeRegressionMetric',\n",
    "                'arguments':{'data':None, 'tree':None, 'estim':estim, 'feats':colPred, 'metric':'RMSE', 'optimGoal':parmsGP['optimGoal']}}\n",
    "elif respType == 'C':\n",
    "    # for a discrete target\n",
    "    estim = DecisionTreeClassifier(max_depth=5, min_samples_leaf=20)\n",
    "    parmsGP['optimGoal'] = 1\n",
    "    parmsObj = {'function':'TreeClassificationMetric',\n",
    "                'arguments':{'data':None, 'tree':None, 'estim':estim, 'feats':colPred, 'metric':'accuracy', 'optimGoal':parmsGP['optimGoal']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the GP - hold on to your butts\n",
    "randSeed = None#42\n",
    "verb = False\n",
    "MSims = 1\n",
    "\n",
    "# init\n",
    "bestTrees = [None]*MSims\n",
    "bestScores = [None]*MSims\n",
    "genBestss = [None]*MSims\n",
    "genScoress = [None]*MSims\n",
    "randSeeds = [None]*MSims\n",
    "timeStamps = [None]*MSims\n",
    "figGPProgresss = [None]*MSims\n",
    "seedTrees = []\n",
    "seedFuncs = []\n",
    "\n",
    "# ignore all warnings - may be a very bad idea\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for sim in range(MSims):\n",
    "        print('Executing GP %d of %d'%(sim+1, MSims))\n",
    "        bestTrees[sim], bestScores[sim], genBestss[sim], genScoress[sim],\\\n",
    "        randSeeds[sim], timeStamps[sim], figGPProgresss[sim] = RunGP(parmsGP, parmsData, parmsObj, nodeMeta, seedTrees, verb, randSeed)\n",
    "        # add the best tree to seed the next GP run, if new\n",
    "        bstFunc = bestTrees[sim].function\n",
    "        try:\n",
    "            seedFuncs.index(bstFunc)\n",
    "        except ValueError:\n",
    "            # this best is new, so add\n",
    "            seedTrees.append(bestTrees[sim])\n",
    "            seedFuncs.append(bstFunc)\n",
    "\n",
    "# get the overall best\n",
    "bestIndx = np.argmax(parmsGP['optimGoal']*np.array(bestScores))\n",
    "bestScore = bestScores[bestIndx]\n",
    "bestTree = bestTrees[bestIndx]\n",
    "timeStamp = timeStamps[bestIndx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' evaluate the tree predictions '''\n",
    "# choose the tree\n",
    "tree = bestTree\n",
    "# score it\n",
    "objFunc = parmsObj['function']\n",
    "objArgs = parmsObj['arguments'] \n",
    "objArgs['data'] = data\n",
    "objArgs['tree'] = tree.function\n",
    "objArgs['feats'] = colPred\n",
    "objStr = '%s_%s'%(objFunc, ('_'.join(['%s%r'%(key, val) for (key, val) in objArgs.items()\n",
    "                                      if key not in ['data', 'tree', 'feats']])).replace(\"'\",''))\n",
    "score, preds, objModel = globals()[objFunc](**objArgs)\n",
    "print(tree)\n",
    "print('Score = %0.3f'%score)\n",
    "\n",
    "# create the tree function\n",
    "treeFunc = tree.function\n",
    "for feat in colPred:\n",
    "    treeFunc = treeFunc.replace(feat, 'data.'+feat)\n",
    "\n",
    "# add the tree results & compute error\n",
    "data['treePred'] = eval(treeFunc)\n",
    "data['treeErr'] = data['target'] - data['treePred']\n",
    "\n",
    "# talk\n",
    "display(data.head())\n",
    "\n",
    "# plot\n",
    "resPltTit = 'GP Performance: %s = %0.3f'%(tree.function, score)\n",
    "figGPPerformance = ResultsPlots(data, sequenceCol='_yearID', responseCol='target',\n",
    "                                predCol='treePred', resdCol='treeErr', colorCol=None,\n",
    "                                overall_title=resPltTit, plot_colors=('red',)*4)\n",
    "plyoff.plot(figGPPerformance, filename='../output/GPPerformance_%s_%s_%s.html'\\\n",
    "            %(parmsData['name'], timeStamp, objStr), auto_open=True, include_mathjax='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation between target, predition, and features\n",
    "cols = [response, 'treePred']\n",
    "cols.extend(colPred)\n",
    "figCorr = correlationsPlot(data[cols].corr(), plotTitl='Prediction & Feature Correlations Plot', trcLims=(0.0, 0.5, 0.75, 0.9, 1.0), tweaks=(20, None, None, 1.1))\n",
    "plyoff.plot(figCorr, filename='../output/GPPredCorrMatrix_%s_%s_%s.html'%(parmsData['name'], timeStamp, objStr), auto_open=True, include_mathjax='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' try a model '''\n",
    "# setup predictor columns\n",
    "cols = ['treePred']\n",
    "cols.extend(colPred)\n",
    "\n",
    "# use recursive feature elimination with CV to select some features\n",
    "K = 5\n",
    "selector = RFECV(estimator=estim, min_features_to_select=K, verbose=0, n_jobs=-1)\n",
    "selector.fit(X=data[cols].values, y=data['target'].values)\n",
    "\n",
    "# get best features\n",
    "colSelPred = [c for r, c in zip(selector.ranking_, cols) if r == 1]\n",
    "print('Selected Features: %s'%colSelPred)\n",
    "print('Tree prediction is%s in the selected features!'%(['', ' not']['treePred' in colSelPred]))\n",
    "\n",
    "# fit a model with best features after scaling\n",
    "sdata = StandardScaler().fit_transform(data[colSelPred].values)\n",
    "estim.fit(X=sdata, y=data['target'].values)\n",
    "data['modelPred'] = estim.predict(X=data[colSelPred].values)\n",
    "data['modelErr'] = data['target'] - data['modelPred']\n",
    "\n",
    "# show feature importances\n",
    "if hasattr(estim, 'coef_'):\n",
    "    featimport = pd.DataFrame(index=colSelPred, data=estim.coef_, columns=['Coefficient'])\n",
    "    featimport['absval'] = featimport['Coefficient'].abs()\n",
    "    featimport = featimport.sort_values(by='absval', ascending=False, inplace=False).drop(columns='absval', inplace=False)\n",
    "    display(featimport)\n",
    "elif hasattr(estim, 'feature_importances_'):\n",
    "    featimport = pd.DataFrame(index=colSelPred, data=estim.feature_importances_, columns=['Feature Importance'])\n",
    "    featimport.sort_values(by='Feature Importance', ascending=False, inplace=True)\n",
    "    display(featimport)\n",
    "else:\n",
    "    print('No feature importance information')\n",
    "\n",
    "\n",
    "# plot\n",
    "resPltTit = 'Best Model Performance: %s = %0.3f'%(tree.function, score)\n",
    "figModel = ResultsPlots(data, sequenceCol='_yearID', responseCol='target',\n",
    "                                predCol='modelPred', resdCol='modelErr', colorCol=None,\n",
    "                                overall_title=resPltTit, plot_colors=('red',)*4)\n",
    "plyoff.plot(figGPPerformance, filename='../output/MOdelPerformance_%s_%s_%s.html'\\\n",
    "            %(parmsData['name'], timeStamp, objStr), auto_open=True, include_mathjax='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a6936-20d5-450e-b181-d1535735f154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
