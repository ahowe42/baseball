{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floating-latex",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use the GP to Predict Team Season Results Using Player Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import ipdb\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "import warnings\n",
    "import sys\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import chart_studio.plotly as ply\n",
    "import chart_studio.tools as plytool\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as plyoff\n",
    "import plotly.subplots as plysub\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my imports\n",
    "sys.path.append('../src/')\n",
    "from util.Utils import *\n",
    "from GP.GP import *\n",
    "from GP.FunctionTree import *\n",
    "from GP.Objective import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-october",
   "metadata": {},
   "source": [
    "## Load and Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' load the data '''\n",
    "# open\n",
    "dbFile = '../data/baseballdata.db'\n",
    "dbConn = sqlite3.connect(dbFile)\n",
    "# query\n",
    "sql = 'SELECT * FROM NLALRegularSeasonTeamStatsRanks;'\n",
    "data = pd.read_sql(sql, dbConn)\n",
    "display(data.head())\n",
    "# close\n",
    "dbConn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' final data prep ''' \n",
    "# drop a few columns\n",
    "data.drop(columns=['_G', '_L'], inplace=True)\n",
    "# encode division & league win columns as binary\n",
    "data['_DivWin'] = np.where(data['_DivWin'] == 'Y', True, False)\n",
    "data['_LgWin'] = np.where(data['_LgWin'] == 'Y', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping pitcher's wins & losses for obvious reasons; can add this back when using year t stats\n",
    "# to predict year t+1 performance\n",
    "data.drop(columns=['P_Win', 'P_Loss'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column roles\n",
    "colID = ['_yearID', '_lgID', '_difID', '_teamID', 'Team']\n",
    "colResp = ['_Rank', '_divWin', '_LgWin', 'WinPerc', 'WinLosPerc'] # all potentially useful targets\n",
    "colPred = [col for col in data.columns if col[:2] in ['F_', 'B_', 'P_']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-expense",
   "metadata": {},
   "source": [
    "## Run the GP\n",
    "### How do player stats best relate to team performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target column\n",
    "print(colResp)\n",
    "response = colResp[int(input('Enter the index of the potential response column to use: '))]\n",
    "print('Reponse = %s'%response)\n",
    "data['target'] = data[response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' prepare GP input parameters '''\n",
    "# GP parameters\n",
    "parmsGP = {'showTopSubs':10, 'populSize':500, 'numGens':200, 'noChangeTerm':180, 'convgCrit':0.00001,\n",
    "           'elitism':True, 'mateType':1, 'probXover':0.8, 'probMutate':0.3, 'plotFlag':True,\n",
    "           'printFreq':10, 'maxDepth':4, 'probPrune':0.4, 'probSimp':0.2}\n",
    "# data parameters\n",
    "parmsData = {'data':data, 'name':'NLALRegularSeasonTeamStatsRanks_%s'%response}\n",
    "\n",
    "# set the possible node values\n",
    "ops = ['ad', 'sb', 'ml', 'dv', 'pw', 'mx', 'mn']\n",
    "consts = [0, 1, 2, 3, 10, 100]\n",
    "nodeMeta = OrderedDict() # must be orderd by descending weight - [values, length, weight] \n",
    "nodeMeta['op'] = [ops, len(ops), 0.5]\n",
    "nodeMeta['feat'] = [colPred, len(colPred), 0.25]\n",
    "nodeMeta['const'] = [consts, len(consts), 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' objective parameters '''\n",
    "# for a continuous target\n",
    "parmsGP['optimGoal'] = -1\n",
    "parmsObj = {'function':'TreeRegressionMetric',\n",
    "            'arguments':{'data':None, 'tree':None, 'estim':None, 'feats':colPred, 'metric':'RMSE', 'optimGoal':parmsGP['optimGoal']}}\n",
    "\n",
    "'''# for a discrete target\n",
    "parmsGP['optimGoal'] = 1\n",
    "parmsObj = {'function':'TreeClassificationMetric',\n",
    "            'arguments':{'data':None, 'tree':None, 'estim':None, 'feats':colPred, 'metric':'accuracy', 'optimGoal':parmsGP['optimGoal']}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the GP - hold on to your butts\n",
    "randSeed = None#42\n",
    "verb = False\n",
    "MSims = 1\n",
    "\n",
    "# init\n",
    "bestTrees = [None]*MSims\n",
    "bestScores = [None]*MSims\n",
    "genBestss = [None]*MSims\n",
    "genScoress = [None]*MSims\n",
    "randSeeds = [None]*MSims\n",
    "timeStamps = [None]*MSims\n",
    "figGPProgresss = [None]*MSims\n",
    "seedTrees = []\n",
    "seedFuncs = []\n",
    "\n",
    "# ignore all warnings - may be a very bad idea\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for sim in range(MSims):\n",
    "        print('Executing GP %d of %d'%(sim+1, MSims))\n",
    "        bestTrees[sim], bestScores[sim], genBestss[sim], genScoress[sim],\\\n",
    "        randSeeds[sim], timeStamps[sim], figGPProgresss[sim] = RunGP(parmsGP, parmsData, parmsObj, nodeMeta, seedTrees, verb, randSeed)\n",
    "        # add the best tree to seed the next GP run, if new\n",
    "        bstFunc = bestTrees[sim].function\n",
    "        try:\n",
    "            seedFuncs.index(bstFunc)\n",
    "        except ValueError:\n",
    "            # this best is new, so add\n",
    "            seedTrees.append(bestTrees[sim])\n",
    "            seedFuncs.append(bstFunc)\n",
    "\n",
    "# get the overall best\n",
    "bestIndx = np.argmax(parmsGP['optimGoal']*np.array(bestScores))\n",
    "bestScore = bestScores[bestIndx]\n",
    "bestTree = bestTrees[bestIndx]\n",
    "timeStamp = timeStamps[bestIndx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' evaluate the tree predictions '''\n",
    "# choose the tree\n",
    "tree = bestTree\n",
    "# score it\n",
    "objFunc = parmsObj['function']\n",
    "objArgs = parmsObj['arguments'] \n",
    "objArgs['data'] = data\n",
    "objArgs['tree'] = tree.function\n",
    "objArgs['feats'] = colPred\n",
    "objStr = '%s_%s'%(objFunc, ('_'.join(['%s%r'%(key, val) for (key, val) in objArgs.items()\n",
    "                                      if key not in ['data', 'tree', 'feats']])).replace(\"'\",''))\n",
    "score, preds, linreg = globals()[objFunc](**objArgs)\n",
    "print(tree)\n",
    "print('Score = %0.3f'%score)\n",
    "\n",
    "# create the tree function\n",
    "treeFunc = tree.function\n",
    "for feat in colPred:\n",
    "    treeFunc = treeFunc.replace(feat, 'data.'+feat)\n",
    "\n",
    "# add the tree results & compute error\n",
    "data['tree'] = eval(treeFunc)\n",
    "data['error'] = data['target'] - data['tree']\n",
    "\n",
    "# talk\n",
    "display(data.head())\n",
    "\n",
    "# plot\n",
    "resPltTit = 'GP Performance: %s = %0.3f'%(tree.function, score)\n",
    "figGPPerformance = ResultsPlots(data, sequenceCol='_yearID', responseCol='target',\n",
    "                                predCol='tree', resdCol='error', colorCol=None,\n",
    "                                overall_title=resPltTit, plot_colors=('red',)*4)\n",
    "plyoff.plot(figGPPerformance, filename='../output/GPPerformance_%s_%s_%s.html'\\\n",
    "            %(parmsData['name'], timeStamp, objStr), auto_open=True, include_mathjax='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation between target, predition, and features\n",
    "cols = [response, 'tree']\n",
    "cols.extend(colPred)\n",
    "figCorr = correlationsPlot(data[cols].corr(), plotTitl='Prediction & Feature Correlations Plot', trcLims=(0.0, 0.5, 0.75, 0.9, 1.0), tweaks=(20, None, None, 1.1))\n",
    "plyoff.plot(figCorr, filename='../output/GPPredCorrMatrix_%s_%s_%s.html'%(parmsData['name'], timeStamp, objStr), auto_open=True, include_mathjax='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-nickel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
